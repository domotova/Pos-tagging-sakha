# Pos-tagging-sakha
## Актуальность задачи.
В данной работе рассмотрена задача морфологического анализа - частеречная разметка якутских текстов. Под этим понимается этап автоматического определения частей речи слов в тексте.

Сложность разработки объясняется тем, что нет размеченных данных для обучения, а также якутский язык сам по себе имеет сложную структуру.
___
### Якутский язык и его части речи. Особенности разметки
__Якутский язык относится к тюркской группе языков и обладает следующими свойствами:__
* Агглютинация. Словообразование происходит за счет добавления к основе аффиксов
* Аналитические приемы образования слов: сложение основ
* Гармония гласных: гласные звуки следуют друг за другом в строго определенном порядке.

Разметка ведется в формате CoNLL-U (URL: https://universaldependencies.org/format.html). Каждому слову задается метка части речи. В данной работе метками являются следующие:
*	NOUN - аат тыл (существительное)
*	ADJ - даҕааһын аат (имя прилагательное)
*	NUM - ахсаан аат (имя числительное)
*	PRON - солбуйар аат (местоимение)
*	VERB - туохтуур (глагол) 
*	ADV - сыһыат (наречие) 
*	PR - дьөһүөл (?)
*	CONJ - ситим тыл (союз) 
*	PART - эбиискэ (частица)
*  AUX - сыһыан тыл (?) 
*	INTJ - саҥа аллайыы (междометие) 
*	PUNCT - пунктуация 
*  SYM - символлар
*  X - атын (другое)
___

### Сбор датасета.
На данный момент собран корпус, состоящий из 2380 предложений, вручную размеченных по частям речи. Большую благодарность выражаю студентам ИЯКН СВФУ. Корпус находится в папке data с названием postag_sakha.conllu. Код создания корпуса в папке colab_notebooks - To_conllu.ipynb.

Данные для разметки взяты из репозитория sakha-embeddings (URL: https://github.com/nlp-sakha/sakha-embeddings). Это корпус, состоящий из статей якутской Википедии и электронных новостных изданий. Перед разметкой данные были очищены от всех ненужных символов, приведены к единому кодированию символов. Код есть в папке colab_notebooks - _data_clean.ipynb.

___
### Модели машинного обучения.
Здесь представлены две модели машинного обучения: 
* первый основан на сверточной нейронной сети, построенную по идеям статьи 
```
Yu X., Faleńska A., Vu N. T. A general-purpose tagger with convolutional neural networks //arXiv preprint arXiv:1706.01723. – 2017
```
* второй - на рекуррентных нейронных сетях. Выбрана модель Bidirectional LSTM + Wor2vec вложения слов.
___
### Обучение моделей.
__Требования:__
- Python 
- PyTorch 
- Keras

Дополнительные требования можно установить через:
```bash
pip install -r requirements.txt
```
__Для обучения моделей:__

- Модель CNN
Запустите:
```
python train_cnn_postag_sakha.py
```
Обученная модель сохраняется в папке models - cnn_pos.

Чтобы тестировать обученную модель:
```
# Загружаем нужные библиотеки
from utils import char_vocab, UNIQUE_TAGS, tokenize_corpus, POSTagger
import torch

# Загружаем обученную модель
cnn_pos_tagger = POSTagger(torch.load('./models/cnn_pos', map_location={'cuda:0': 'cpu'}), char_vocab, UNIQUE_TAGS, 75, 25)

# Вводим любые предложения, на которых хотим тестить
test_sentences = ['Саха сирин хайыһарга сүүмэрдэммит хамаандата билигин Новосибирскай куоракка үөрэнэр дьарыкка сылдьар .',
                  'М . К . Аммосов аатынан ХИФУ автодорожнай факультетын бастакы кууруһугар үөрэнэбин .']
test_sentences_tokenized = tokenize_corpus(test_sentences, min_token_size=1)

# Печатаем полученные метки слов
for sent_tokens, sent_tags in zip(test_sentences_tokenized, cnn_pos_tagger(test_sentences)):
    print(' '.join('{}-{}'.format(tok, tag) for tok, tag in zip(sent_tokens, sent_tags)))
    print()
```
- Модель BiLSTM + Word2vec

Для тренировки моделей сделайте:
___
### Анализ полученных результатов.
Качество работы алгоритмов классификации на несбалансированных данных традиционно оценивается с помощью точности (precision), полноты (recall) и среднего гармонического точности и полноты классификации (f1-score) по классам. Ниже в таблице приведены точность, полнота и f1-мера нейросети для каждого класса тестовых данных, а в последнем столбце их количество.

|  Tag  | precision  | recall | f1-score | quantity |
| :---: | :---: | :---: | :---: | :---: |
| NOUN  |  0,82      |  0,9   |   0,86   |  3082    |
| ADJ   |  0,65      |  0,62  |   0,63   |   605    |
| NUM   |  0,91      |  0,86  |   0,88   |   281    |
| PRON  |  0,95      |  0,88  |   0,91   |   471    |
| VERB  |  0,83      |  0,83  |   0,83   |   1812   |
| ADV   |  0,59      |  0,38  |   0,46   |   346    |
| PART  |  0,56      |  0,43  |   0,49   |   276    |
| PR    |  0,59      |  0,48  |   0,53   |   233    |
| AUX   |  0,32      |  0,29  |   0,3    |    63    |
| CONJ  |  0,62      |  0,61  |   0,62   |   170    |
| INTJ  |  0,25      |  0,4   |   0,31   |    5     |

Доля верных ответов обученной сверточной нейронной сети равна 78 % на тестовых данных и 84% на обучающих данных. 
___
### Выводы.

* сформирован корпус из 2380 предложений с частеречной разметкой, который опубликован тут в папке data.
* в тестовом наборе данных получена точность 78% при классификации членов предложения по частям речи сверточными нейросетями. Это позволяет использовать разработанную нейросеть для первичной обработки данных для последующего ручного исправления и верификации разметки.
* в ходе исследования были замечены уникальные аффиксы, такие как -ааччы и др., присущие только глаголам или иным частям речи. Это позволяет в дальнейшем организовать правила выявления частей речи.

В дальнейшем будем улучшать точность!
___
