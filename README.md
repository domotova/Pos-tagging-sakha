# Pos-tagging-sakha
## Актуальность задачи.
В данной работе рассмотрена задача морфологического анализа - частеречная разметка якутских текстов. Под этим понимается этап автоматического определения частей речи слов в тексте.

Сложность разработки объясняется тем, что нет размеченных данных для обучения, а также якутский язык сам по себе имеет сложную структуру.
___
### Части речи якутского языка. Особенности разметки
Разметка ведется в формате CoNLL-U (URL: https://universaldependencies.org/format.html). Каждому слову задается метка части речи. В данной работе метками являются следующие:
*	NOUN - аат тыл (существительное)
*	ADJ - даҕааһын аат (имя прилагательное)
*	NUM - ахсаан аат (имя числительное)
*	PRON - солбуйар аат (местоимение)
*	VERB - туохтуур (глагол) 
*	ADV - сыһыат (наречие) 
*	PR - дьөһүөл (?)
*	CONJ - ситим тыл (союз) 
*	PART - эбиискэ (частица)
*  AUX - сыһыан тыл (?) 
*	INTJ - саҥа аллайыы (междометие) 
*	PUNCT - пунктуация 
*  SYM - символлар
*  X - атын (другое)
___

### Сбор датасета.
На данный момент собран корпус, состоящий из 2380 предложений, вручную размеченных по частям речи. Большую благодарность выражаю студентам ИЯКН СВФУ. Корпус находится в папке data с названием postag_sakha.conllu. Код создания корпуса в папке colab_notebooks - To_conllu.ipynb.

Данные для разметки взяты из репозитория sakha-embeddings (URL: https://github.com/nlp-sakha/sakha-embeddings). Это корпус, состоящий из статей якутской Википедии и электронных новостных изданий. Перед разметкой данные были очищены от всех ненужных символов, приведены к единому кодированию символов. Код есть в папке colab_notebooks - _data_clean.ipynb.

___
### Модели машинного обучения.
Здесь представлены две модели машинного обучения: 
* первый основан на сверточной нейронной сети, построенную по идеям статьи 
```
Yu X., Faleńska A., Vu N. T. A general-purpose tagger with convolutional neural networks //arXiv preprint arXiv:1706.01723. – 2017
```
* второй - на рекуррентных нейронных сетях. Выбрана модель Bidirectional LSTM + Wor2vec вложения слов.
___
### Обучение моделей.
__Требования:__
- Python 
- PyTorch 
- Keras

Дополнительные требования можно установить через:
```bash
pip install -r requirements.txt
```
__Для обучения моделей:__

- Модель CNN
1. Обучаем:
```
python train_cnn_postag_sakha.py
```
Обученная модель сохраняется в папке models - cnn_pos.

2. Чтобы тестировать обученную модель:
```
# Загружаем нужные библиотеки
from utils import char_vocab, UNIQUE_TAGS, tokenize_corpus, POSTagger
import torch

# Загружаем обученную модель
cnn_pos_tagger = POSTagger(torch.load('./models/cnn_pos', map_location={'cuda:0': 'cpu'}), char_vocab, UNIQUE_TAGS, 75, 25)

# Вводим любые предложения, на которых хотим тестить
test_sentences = ['Саха сирин хайыһарга сүүмэрдэммит хамаандата билигин Новосибирскай куоракка үөрэнэр дьарыкка сылдьар .',
                  'М . К . Аммосов аатынан ХИФУ автодорожнай факультетын бастакы кууруһугар үөрэнэбин .']
test_sentences_tokenized = tokenize_corpus(test_sentences, min_token_size=1)

# Печатаем полученные метки слов
for sent_tokens, sent_tags in zip(test_sentences_tokenized, cnn_pos_tagger(test_sentences)):
    print(' '.join('{}-{}'.format(tok, tag) for tok, tag in zip(sent_tokens, sent_tags)))
    print()
```
- Модель BiLSTM + Word2vec
1. Сначала скачиваем уже обученные вложения слов Word2vec по ссылке - https://drive.google.com/drive/folders/1NdUxEZU_w_3ORBfxln-ujb1-7mT_8DRy?usp=sharing. Скачиваем два файла: **word2vec_sakha, word2vec_sakha.vectors.npy** в папку word2vec.
2. Потом в папку data создаем файл с названием test.txt, где будут записаны предложения, которые потом будем тестить. Код следующий:
```
with open("./data/test.txt", "w") as f:
    for s in test_sentences: # test_sentences - это питоновский список, состоящий из предложений.
        f.write(s +"\n")
```
3. Обучаем:
```
python train_rnn_postag_sakha.py
```
Обученная модель сохраняется в папке models - rnn_pos.

4. Чтобы тестировать обученную модель:
```
# Загружаем нужные библиотеки
import keras
import numpy as np
from utils import TAGS, rnn_pred

# Загружаем обученную модель
rnn_model = keras.models.load_model("./models/rnn_pos")

# Загружаем преобразованные предложения, которые будем тестить
test = np.load('test_sents.npy')

# Печатаем полученные метки слов
pred = rnn_pred(rnn_model.predict_classes(test))
for i, k in zip(test_sentences, pred):
    print(' '.join('{}-{}'.format(tok, tag) for tok, tag in zip(i.split(), k.split())))
    print()
```
___
### Анализ полученных результатов.
Качество работы на несбалансированных данных традиционно оценивается с помощью точности (precision), полноты (recall) и их среднего гармонического (f1-score) по классам. Ниже в таблицах приведены точность, полнота и f1-мера нейросети для каждого класса тестовых данных, а в последнем столбце их количество.

- Модель CNN

|  Tag  | precision  | recall | f1-score | quantity |
| :---: | :---: | :---: | :---: | :---: |
| NOUN  |  0,87      |  0,88  |   0,88   |  3082    |
| ADJ   |  0,68      |  0,68  |   0,68   |   605    |
| NUM   |  0,93      |  0,87  |   0,9    |   281    |
| PRON  |  0,93      |  0,85  |   0,89   |   471    |
| VERB  |  0,86      |  0,84  |   0,85   |   1812   |
| ADV   |  0,52      |  0,49  |   0,5    |   346    |
| PART  |  0,5       |  0,59  |   0,54   |   276    |
| PR    |  0,66      |  0,64  |   0,65   |   233    |
| AUX   |  0,29      |  0,32  |   0,3    |    63    |
| CONJ  |  0,61      |  0,68  |   0,64   |   170    |
| INTJ  |  0,18      |  0,4   |   0,25   |    5     |

Доля верных ответов обученной сверточной нейронной сети равна 81 % на тестовых данных и 89% на обучающих данных. 

- Модель BiLSTM + Word2vec

|  Tag  | precision  | recall | f1-score | quantity |
| :---: | :---: | :---: | :---: | :---: |
| NOUN  |  0,87      |  0,87  |   0,87   |  3082    |
| ADJ   |  0,74      |  0,63  |   0,68   |   605    |
| NUM   |  0,87      |  0,77  |   0,81   |   281    |
| PRON  |  0,96      |  0,86  |   0,9    |   471    |
| VERB  |  0,86      |  0,81  |   0,83   |   1812   |
| ADV   |  0,60      |  0,52  |   0,56   |   346    |
| PART  |  0,52      |  0,61  |   0,56   |   276    |
| PR    |  0,68      |  0,59  |   0,63   |   233    |
| AUX   |  0,30      |  0,35  |   0,32    |    63    |
| CONJ  |  0,61      |  0,64  |   0,63   |   170    |
| INTJ  |  0,18      |  0,4   |   0,25   |    5     |

Доля верных ответов обученной сверточной нейронной сети равна 80 % на тестовых данных. 
___
### Выводы.

* сформирован корпус из 2380 предложений с частеречной разметкой, который опубликован тут в папке data.
* в тестовом наборе данных получены точности 81% и 80% при классификации членов предложения по частям речи сверточными и рекуррентными нейросетями соответственно. Это позволяет использовать разработанные нейросети для первичной обработки данных для последующего ручного исправления.
* в ходе исследования были замечены уникальные аффиксы, такие как -ааччы и др., присущие только глаголам или иным частям речи. Это позволяет в дальнейшем организовать правила выявления частей речи.

В дальнейшем будем улучшать точность!
___
